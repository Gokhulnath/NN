# -*- coding: utf-8 -*-
"""NN-HW4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ofYsn840k2EuYNWBLBdzyJAh1CGlecuu
"""

import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
import numpy as np
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import mean_squared_error
import pandas as pd


#a
mnist = fetch_openml('mnist_784', version=1)
Xraw, Yraw = mnist['data'], mnist['target']
Yraw = Yraw.astype(np.int8)
fig, axs = plt.subplots(2, 5, figsize=(10, 5))
axs = axs.ravel()

for digit in range(10):
    digit_indices = np.where(Yraw == digit)[0]
    random_index = np.random.choice(digit_indices)
    image = Xraw.iloc[random_index].values.reshape(28, 28)
    axs[digit].imshow(image, cmap='gray')
    axs[digit].set_title(f"Digit: {digit}")
    axs[digit].axis('off')

plt.tight_layout()
plt.show()

#b
d = 50
M = np.random.uniform(0, 1, (d, 784)) / (255 * d)
X_projected = M @ Xraw.T
one_hot_encoder = OneHotEncoder(sparse_output=False, categories='auto')
Y_one_hot = one_hot_encoder.fit_transform(Yraw.values.reshape(-1, 1)).T
X_pseudo_inv = np.linalg.pinv(X_projected.T)
W = X_pseudo_inv @ Y_one_hot.T
values = Yraw.values
reshaped_values = values.reshape(-1, 1)
Y_one_hot = one_hot_encoder.fit_transform(reshaped_values).T

#c
def compute_metrics(d):
    M = np.random.uniform(0, 1, (d, 784)) / (255 * d)
    X_projected = M @ Xraw.T
    X_pseudo_inv = np.linalg.pinv(X_projected.T)
    W = X_pseudo_inv @ Y_one_hot.T
    Y_pred = W.T @ X_projected
    mse = mean_squared_error(Y_one_hot.T, Y_pred.T)
    predicted_labels = np.argmax(Y_pred, axis=0)
    true_labels = np.argmax(Y_one_hot, axis=0)
    mistakes = np.sum(predicted_labels != true_labels)

    return mse, mistakes

d_values = [10, 50, 100, 200, 500]
results = {}

for d in d_values:
    mse, mistakes = compute_metrics(d)
    results[d] = {'MSE': mse, 'Mistakes': mistakes}
    print('d = {}\nMSE = {}\nMistakes = {}'.format(d, mse, mistakes))


#d
def lms_algorithm(X_projected, Y_one_hot, d, eta, epochs):
    n_samples = X_projected.shape[1]
    W = np.zeros((d, 10))
    mse_history = []

    if isinstance(X_projected, pd.DataFrame):
        X_projected = X_projected.values

    for epoch in range(epochs):
        for i in range(n_samples):
            x_i = X_projected[:, i]
            y_i = Y_one_hot[:, i]
            y_pred = W.T @ x_i
            W += eta * np.outer(x_i, (y_i - y_pred))

        Y_pred = W.T @ X_projected
        mse = mean_squared_error(Y_one_hot.T, Y_pred.T)
        mse_history.append(mse)

    return W, mse_history

def compute_mistakes(Y_pred, Y_one_hot):
    predicted_labels = np.argmax(Y_pred, axis=0)
    true_labels = np.argmax(Y_one_hot, axis=0)
    mistakes = np.sum(predicted_labels != true_labels)
    return mistakes

d = 100
eta = 0.001
epochs = 10

M = np.random.uniform(0, 1, (d, 784)) / (255 * d)
X_projected = M @ Xraw.T
W_lms, mse_history = lms_algorithm(X_projected, Y_one_hot, d, eta, epochs)
plt.plot(range(1, epochs + 1), mse_history, marker='o')
plt.title('MSE vs Number of Epochs (LMS)')